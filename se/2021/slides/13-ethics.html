<!DOCTYPE html>
<html>
	<head>
		<meta charset="utf-8" />
		<title></title>
		<link rel="stylesheet" href="slides-style.css" type="text/css">
		<style>
.semi-transparent {
  opacity: 0.5
}
		</style>
	</head>
	<body>
		<textarea id="source">
class: center, middle, main-title

# Software Engineering
Ethics

---
## There's somethin' wrong with the world today

Can you name a few biggest problems?

---
## Ethics

> **Ethics** or moral philosophy is a branch of philosophy that involves systematizing, defending, and **recommending concepts of right and wrong behavior**.
> <br><br>— <cite>Internet Encyclopedia of Philosophy</cite>

???
By naming things we have already applied our ethical judgement to identify things as "wrong". In other words, ethics are a natural part of everyday life.

What is the "right" thing to do in a situation like this?

---
## Two aspects

- Personal ethics
???
- We're talking about general "rules" of what is "right" or "wrong" to do in life - an inner compass.
- Personal ethics helps us take responsibility for our moral choices and their consequences.
- Example of a "right": "Always tell the truth"
- These rules can originate from religion, cultural tradition, philosophy, or other personal beliefs.
- A person applies their personal ethics to everything they do

--
- Professional ethics

???
However, in some lines of work, a personal code of ethics is not enough.
Without a sense of professional ethics, one could justify conduct that seems "acceptable" in their own mind, but not in that of others practicing the same line of work.

For example, wanting to have integrity is great - but what does integrity look like in a particular profession?
What sort of specific work practices demonstrate integrity, or a lack of it?
This is something that professional codes of ethics can help us learn to see.

Often formulated in formal codes or standards to which all members of a profession are held, such as those of medical ethics.

Example: "Hippocratic Oath". Nowadays the main pillars are:
- Seeking benefit for the patient
- Avoiding harm for the patient
- Freedom to choose treatment (where the patient is able to)
- Ensuring fairness

---
## Engineering ethics

- Origins in the 19th-20th century
???
- Engineering ethics - field that examines and sets the obligations by engineers to society, to their clients, and to the profession.
- Structural failures, especially bridge
    - Quebec Bridge (Canada) 1907 - design error, bridge unable to support own weight. 75 killed, 11 injured, bridge destroyed
    - Kärevere Bridge (Estonia) 1928 - serious design flaws and too small share of cement in concrete
    - [Tacoma Narrows Bridge (US) 1940](https://en.wikipedia.org/wiki/Tacoma_Narrows_Bridge_(1940)) - aerodynamically poor design
--
- Engineering societies defining their codes of ethics
--
- Licensing
???
- Formal credentials as a requirement to practice
- Similar to medics requiring medical licences. Or drivers requiring driving licenses.

---
## [IEEE/ACM Code of Ethics](https://www.computer.org/education/code-of-ethics)

> Because of their roles in developing software systems, **software engineers have significant opportunities to do good or cause harm** [...].<br><br>
> To ensure, as much as possible, that their efforts will be used for good, software engineers must commit themselves to making software engineering a **beneficial** and **respected** profession [...].<br><br>
> The Code prescribes these as **obligations of anyone claiming to be or aspiring to be a software engineer**.

---
## [IEEE/ACM Code of Ethics](https://www.computer.org/education/code-of-ethics)

> These Principles should influence software engineers<br>
> to consider broadly **who is affected** by their work;<br>
> to examine if they and their colleagues are **treating other human beings with due respect**;<br>
> to consider how the **public**, if reasonably well informed, would view their decisions;<br>
> to analyze how the **least empowered** will be affected by their decisions;<br>
> and to consider whether their acts would be **judged worthy of the ideal professional** working as a software engineer.<br><br>
> In all these judgments **concern for the health, safety and welfare of the public is primary**; that is, the “Public Interest” is central to this Code.

???
However, even in this generality, the Code provides support for software engineers and managers of software engineers who need to take positive action in a specific case
by documenting the ethical stance of the profession. The Code provides an ethical foundation to which individuals within teams and the team as a whole can appeal. 
The Code helps to define those actions that are ethically improper to request of a software engineer or teams of software engineers.

If anyone asks you to do something that would breach the code of ethics, you should NOT do it.

---
## Examples of unethical behaviour

- What examples could you name?
--
- [A number of reports from Facebook (2021)](https://www.wsj.com/articles/the-facebook-files-11631713039)
???
- Leaked documents describing what the company knew about how it contributed to harms ranging from its impact on teens’ mental health and the extent of misinformation on its platforms, to human traffickers’ open use of its services.
 The documents paint a picture of a company that is often aware of the harms to which it contributes—but is either unwilling or unable to act against them.
--
- [Google & Apple removing "smart voting" app prior to election in Russia (2021)](https://www.nytimes.com/2021/09/17/world/europe/russia-navalny-app-election.html)
???
- A form of censorship due to the pressure from the Russian authorities.
--
- [Apple and Samsung fined for deliberately slowing down phones (2018)](https://www.theguardian.com/technology/2018/oct/24/apple-samsung-fined-for-slowing-down-phones)
--
- [Google working on a censored search engine in China (2018)](https://theintercept.com/2018/08/01/google-china-search-engine-censorship/)
--
- [Dieselgate (2008-2015)](https://en.wikipedia.org/wiki/Volkswagen_emissions_scandal)
???
- Volkswagen had intentionally programmed their diesel-engined vehicles to limit their emissions during laboratory testing, while the emissions in real-world driving exceeded the standard by a factor between 5 and 35.

---
## Some other areas of concern

- Addictive design
???
- 1. Social networks optimize for continuous interaction ("The Social Dilemma" - documentary on Netflix)
- 1. Clickbait news
--
- Questionable personal data ownership
???
- 2. Tracking users. A lot of data. What to do with it?
- 2. In EU GDPR tries to address this to some extent
--
- Algorithmic bias ([1](https://blog.acolyer.org/2018/05/24/algorithmic-glass-ceiling-in-social-networks-the-effects-of-recommendation-on-social-diversity/), [2](https://www.nytimes.com/2020/11/26/us/un-panel-technology-in-policing-can-reinforce-racial-bias.html))
???
- 3. A bias is "an inclination or prejudice for or against one person or group, especially in a way considered to be unfair"
- 3. AI can be biased against entire populations
--
- Weak security and PII protection
???
- 4. Security as an afterthough
--
- Trustworthiness of information
???
- 5. Maps and disputed border territories - some map providers used to assign a disputed territory to different countries, depending on where you were viewing the map from
--
- *Black Mirror* ([1](https://blog.acolyer.org/2018/05/14/re-coding-black-mirror-part-i/), [2](https://blog.acolyer.org/2018/05/15/re-coding-black-mirror-part-ii/), [3](https://blog.acolyer.org/2018/05/16/re-coding-black-mirror-part-iii/), [4](https://blog.acolyer.org/2018/05/17/re-coding-black-mirror-part-iv/), [5](https://blog.acolyer.org/2018/05/18/re-coding-black-mirror-part-v/))

---
## More on algorithmic bias

- AI is often perceived as objective
--
- The reality is that it is as good as the data it was trained on
???
- The inputs to a machine learning model are a description of **what is**. If we train a model on that data, the outputs of the model will treat **what is** as if it were what **should be**. We have made a sophisticated machine for reinforcing the status quo.
--
- Hypothetical example: Building an AI that generates stories ([inspiration](https://blog.acolyer.org/2020/12/08/bias-in-word-embeddings/))
???
- We train our AI to learn the meaning of words from all written texts - books, articles, social media posts, etc.
- Then we train our AI to use the words to produce random stories
- Outcome: our stories will likely have racist, sexist, nationalistic, and homophobic sentiments.
- Because a large amount of written texts is.
- Bias in, bias out.

--
- Real example: [Social recommendations](https://blog.acolyer.org/2018/05/24/algorithmic-glass-ceiling-in-social-networks-the-effects-of-recommendation-on-social-diversity/)
???
- Individuals tend to favour interactions with similar peers, especially in majority/dominanting groups
- This influences both organic connection growth (user choices) and recommendations (algorithmic)
- Outcome: The inequality of representation of historically under-represented groups increases to higher levels
- Problem: How to correct a seemingly neutral algorithm when the structure it exploits is not fair to begin with

--
- Real example: [Risk of future crime](https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing)
???
- A model-based rating a defendant's risk of future crime is given to a judge
- Outcome: The formula was particularly likely to falsely flag black defendants as future criminals, wrongly labeling them this way at almost twice the rate as white defendants.
- Outcome: White defendants were mislabeled as low risk more often than black defendants.
- Likely based on historic data. The United States locks up far more people than any other country, a disproportionate number of them black.

---
## Gender gap

- Have you noticed the gender gap in IT?
- What do you think of it?

???
- That's just the way it is, everything is normal - but is it?
- It's a very complicated topic. A few things to consider
- Education
- Girls are as interested/good with math/logic/technology as boys are (at young age). The way society is/and lively stereotypes are a significant factor of increasing the gap.
- The conditions under which women study IT are not the asme as those experienced by men
    - Women perform significantly more unpaid work
    - Being in an underrepresented group can result in pressure to fit in / experience of hostility/sexism
    - Policies favoring competition over cooperation tend to advantage men
    - Recent research: "men of average intelligence think they are more intelligent than tho-thirds of people". This was not observed in women.
- Career
    - Job ads: same job, different wording and photo - the percentage of female applicants jumped up from 5% to 40%. Demo: https://gender-decoder.katmatfield.com
    - On average, women are paid less for performing the exact same job
    - Women get promoted less often, and often not to the top levels ("glass ceiling")

---
## Diversity is not just about the gender

- Age
- Race
- Ethnicity
- Sexual orientation
- (Dis)ability
- etc.

The goal is a culture where everyone has a voice, feels valued, and is treated fairly.

---
## Not only *how*, but also *what*

- We touched upon *how* to build software
???
- What is "the right" thing to do in some situations, what biases to try to avoid and compensate for, etc.
--
- But we also have control over *what* software we build
???
- Recall some of the "problems of the world" we named before. There are also "UN Sustainable Development Goals", or "EU Green Deal".
- You could make your career in helping solve that problem through research or building software. It is possible, and it's your choice.
--
- Some inspiration:
    - [What can a technologist do about climate change?](http://worrydream.com/#!/ClimateChange)
???
- Huge amount of data and resources
--
    - [80 000 hours](https://80000hours.org/)
???
- A nonprofit aiming to help you find a meaningful high-impact career. They argue that your career is your biggest opportunity to make a difference.

---
## Resources

Mandatory:
- [Code of Ethics](https://www.computer.org/education/code-of-ethics) (full text)

Recommended:
- Talk: ["Born for IT? - How the Image of Software Developers came about" by Birgitta Böckeler](https://www.youtube.com/watch?v=wk1r4XaWwsM)
- Article: [An Introduction to Software Engineering Ethics](https://www.scu.edu/media/ethics-center/technology-ethics/Students.pdf)
- Website: [80 000 hours](https://80000hours.org/)

Also:
- Book: [Invisible Women: Data Bias in a World Designed for Men](https://www.goodreads.com/book/show/41104077-invisible-women)
- Article: [What can a technologist do about climate change?](http://worrydream.com/#!/ClimateChange)

---
class: middle, center
# Questions?

</textarea>
<script src="https://remarkjs.com/downloads/remark-0.15.0.min.js"></script>
<!-- Remark Wiki: https://github.com/gnab/remark/wiki -->
<script>
    const slideshow = remark.create({
            highlightStyle: 'github',
            highlightLines: 'true',
            highlightSpans: true,
            ratio: '16:9',
            countIncrementalSlides: false
    });
</script>
</body>
</html>